{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Clone the Repository\n",
        "!git clone https://github.com/FaridRash/HW-SW-B Big-Data"
      ],
      "metadata": {
        "id": "kXunvqTTCLDe",
        "outputId": "deaf3cce-a232-4d50-ccab-6f9d75f9c8ca",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Big-Data'...\n",
            "remote: Enumerating objects: 372, done.\u001b[K\n",
            "remote: Counting objects: 100% (156/156), done.\u001b[K\n",
            "remote: Compressing objects: 100% (151/151), done.\u001b[K\n",
            "remote: Total 372 (delta 93), reused 7 (delta 4), pack-reused 216 (from 1)\u001b[K\n",
            "Receiving objects: 100% (372/372), 19.63 MiB | 19.40 MiB/s, done.\n",
            "Resolving deltas: 100% (188/188), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "bo7_b6YmZ9gw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **The libraries**"
      ],
      "metadata": {
        "id": "FloHhoaganwU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "pgTTR6tkjYpm"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import sklearn\n",
        "import seaborn as sns\n",
        "import plotly.figure_factory as ff\n",
        "from statsmodels.tools.tools import add_constant\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from scipy.cluster.hierarchy import dendrogram, linkage\n",
        "from sklearn.cluster import AgglomerativeClustering\n",
        "from sklearn.cluster import DBSCAN\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Fetching**"
      ],
      "metadata": {
        "id": "E9OrS0ufaS_8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "jjaSTj4_pBaa",
        "outputId": "d74602ec-82cb-4e0c-d2f7-24c3fb93b708",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 322
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/Big-Data/Data/xAPI-Edu-Data.csv'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-b601fceb6f80>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Load the dataset from the specified path into a pandas DataFrame\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/Big-Data/Data/xAPI-Edu-Data.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1881\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    874\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/Big-Data/Data/xAPI-Edu-Data.csv'"
          ]
        }
      ],
      "source": [
        "# Load the dataset from the specified path into a pandas DataFrame\n",
        "data = pd.read_csv('/content/Big-Data/Data/xAPI-Edu-Data.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9V7PjdffpqKF"
      },
      "outputs": [],
      "source": [
        "# Display the first 10 rows of the DataFrame to get an overview of the data\n",
        "data.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6lYCW9VArJkH"
      },
      "outputs": [],
      "source": [
        "# Print the shape of the DataFrame to know the number of rows and columns\n",
        "print(data.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dk--Idhfqvik"
      },
      "outputs": [],
      "source": [
        "# Display a concise summary of the DataFrame, including data types and non-null counts\n",
        "data.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U0g4p8nZqyB5"
      },
      "outputs": [],
      "source": [
        "# Generate descriptive statistics for the numerical columns in the DataFrame\n",
        "data.describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Data Cleaning**"
      ],
      "metadata": {
        "id": "wenZyCrsOgd8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sns.heatmap(data.isnull(), cbar=False, yticklabels=False)"
      ],
      "metadata": {
        "id": "5ppBs6vh1C5e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "51oE3vcbrTnY"
      },
      "outputs": [],
      "source": [
        "# Extract the column names into a list\n",
        "columns_list = data.columns.tolist()\n",
        "\n",
        "# Enumerate through the list of column names and print each with its index\n",
        "for index, column_name in enumerate(columns_list):\n",
        "    print(f\"{index + 1}. {column_name}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1o2mFpaAymOf"
      },
      "outputs": [],
      "source": [
        "# Calculate the number of missing values in each column\n",
        "missing_data = data.isnull().sum()\n",
        "\n",
        "# Print the missing values for each column\n",
        "print(\"Missing values in each column:\")\n",
        "print(missing_data)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RIY0UZGd20Mm"
      },
      "outputs": [],
      "source": [
        "# Check if there are any duplicate rows and count the number of duplicate rows\n",
        "are_duplicates = data.duplicated().any()\n",
        "num_duplicates = data.duplicated().sum()\n",
        "\n",
        "# Print the results\n",
        "are_duplicates, num_duplicates\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8ocA5uKo2-dV"
      },
      "outputs": [],
      "source": [
        "# Remove duplicate rows from the DataFrame\n",
        "data.drop_duplicates(inplace=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N_T19tIa3BCL"
      },
      "outputs": [],
      "source": [
        "# Recheck if there are any duplicate rows and count the number of duplicate rows after removing them\n",
        "are_duplicates_after_removal = data.duplicated().any()\n",
        "num_duplicates_after_removal = data.duplicated().sum()\n",
        "\n",
        "# Print the results to confirm duplicates have been removed\n",
        "are_duplicates_after_removal, num_duplicates_after_removal\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Encoding**"
      ],
      "metadata": {
        "id": "8p_AhgCEOADz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FWGXBAgh4IX9"
      },
      "outputs": [],
      "source": [
        "# Select columns with object data type\n",
        "object_columns = data.select_dtypes(include=['object']).columns.tolist()\n",
        "\n",
        "# Iterate over each object column and print the unique values\n",
        "for col_index in range(len(object_columns)):\n",
        "    col_name = object_columns[col_index]\n",
        "    unique_values = data[col_name].unique()\n",
        "    print(f\"Unique values for column '{col_name}':\")\n",
        "    for value in unique_values:\n",
        "        print(value)\n",
        "    print()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_uniques_alternative(df, columns):\n",
        "    \"\"\"\n",
        "    Returns a dictionary of unique values for specified columns in the DataFrame.\n",
        "\n",
        "    :param df: pandas DataFrame\n",
        "    :param columns: list of column names\n",
        "    :return: dictionary with column names as keys and lists of unique values as values\n",
        "    \"\"\"\n",
        "    unique_values_dict = {}\n",
        "    for column in columns:\n",
        "        unique_values_dict[column] = df[column].unique().tolist()\n",
        "    return unique_values_dict\n"
      ],
      "metadata": {
        "id": "w2jlJatbNYnl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_categorical_columns_alternative(df):\n",
        "    \"\"\"\n",
        "    Returns a list of column names that have a data type of 'object'.\n",
        "\n",
        "    :param df: pandas DataFrame\n",
        "    :return: list of categorical column names\n",
        "    \"\"\"\n",
        "    categorical_columns = []\n",
        "    for column in df.columns:\n",
        "        if df.dtypes[column] == 'object':\n",
        "            categorical_columns.append(column)\n",
        "    return categorical_columns\n"
      ],
      "metadata": {
        "id": "JtPo3ZCyNZu1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uGEJZ0E-ULx5"
      },
      "outputs": [],
      "source": [
        "# Get unique values for all categorical columns in the DataFrame\n",
        "unique_values_dict = get_uniques_alternative(data, get_categorical_columns_alternative(data))\n",
        "\n",
        "# Display the dictionary of unique values\n",
        "unique_values_dict\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Display the column names of the DataFrame\n",
        "data.columns\n"
      ],
      "metadata": {
        "id": "lKzSmk6i7MxF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate and print the normalized value counts of 'gender' grouped by 'Class'\n",
        "print(data.groupby(['Class'])['gender'].value_counts(normalize=True), '\\n', '\\n', '\\n')\n",
        "\n",
        "# Calculate and print the normalized value counts of 'NationalITy' grouped by 'Class'\n",
        "print(data.groupby(['Class'])['NationalITy'].value_counts(normalize=True), '\\n', '\\n', '\\n')\n",
        "\n",
        "# Calculate and print the normalized value counts of 'PlaceofBirth' grouped by 'Class'\n",
        "print(data.groupby(['Class'])['PlaceofBirth'].value_counts(normalize=True), '\\n', '\\n', '\\n')\n",
        "\n",
        "# Calculate and print the normalized value counts of 'StageID' grouped by 'Class'\n",
        "print(data.groupby(['Class'])['StageID'].value_counts(normalize=True), '\\n', '\\n', '\\n')\n"
      ],
      "metadata": {
        "id": "WqDiTe8P542h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oxsCGu-1WpSh"
      },
      "outputs": [],
      "source": [
        "# Categorize the features into binary, ordinal, and nominal categories\n",
        "binary_features = ['gender', 'Semester', 'Relation', 'ParentAnsweringSurvey', 'ParentschoolSatisfaction', 'StudentAbsenceDays']\n",
        "ordinal_features = ['StageID', 'GradeID']\n",
        "nominal_features = ['NationalITy', 'PlaceofBirth', 'SectionID', 'Topic']\n",
        "\n",
        "# Specify the target column\n",
        "target_column = 'Class'\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "06NvvvqwWp2X"
      },
      "outputs": [],
      "source": [
        "# Define the positive values for binary encoding of binary features\n",
        "binary_positive_values = ['M', 'S', 'Father', 'Yes', 'Good', 'Above-7']\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PzDhY0CZW2Px"
      },
      "outputs": [],
      "source": [
        "# Define the ordering for the 'StageID' ordinal feature\n",
        "stage_ordering = ['lowerlevel', 'MiddleSchool', 'HighSchool']\n",
        "\n",
        "# Define the ordering for the 'GradeID' ordinal feature\n",
        "grade_ordering = ['G-02', 'G-04', 'G-05', 'G-06', 'G-07', 'G-08', 'G-09', 'G-10', 'G-11', 'G-12']\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IZtyjHb0W8XP"
      },
      "outputs": [],
      "source": [
        "# Define prefixes for nominal features to be used in encoding\n",
        "nominal_prefixes = ['N', 'B', 'S', 'T']\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GChW0id5XAV0"
      },
      "outputs": [],
      "source": [
        "# Function to perform binary encoding on a specified column\n",
        "def binary_encode_alternative(df, column, positive_value):\n",
        "    df = df.copy()\n",
        "    df[column] = df[column].map(lambda x: 1 if x == positive_value else 0)\n",
        "    return df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yy3g_FQ9XLju"
      },
      "outputs": [],
      "source": [
        "# Function to perform ordinal encoding on a specified column\n",
        "def ordinal_encode_alternative(df, column, ordering):\n",
        "    df = df.copy()\n",
        "    df[column] = df[column].map(ordering.index)\n",
        "    return df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M18Zw_0QXQ9z"
      },
      "outputs": [],
      "source": [
        "# Function to perform one-hot encoding on a specified column\n",
        "def onehot_encode_alternative(df, column, prefix):\n",
        "    df = df.copy()\n",
        "    dummies = pd.get_dummies(df[column], prefix=prefix).astype(int)\n",
        "    df = df.join(dummies).drop(column, axis=1)\n",
        "    return df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "de0T_1s3XWIX"
      },
      "outputs": [],
      "source": [
        "# Apply binary encoding to each feature in the binary_features list\n",
        "for feature, positive_value in zip(binary_features, binary_positive_values):\n",
        "    data = binary_encode_alternative(data, feature, positive_value)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bywMHaHXbr4I"
      },
      "outputs": [],
      "source": [
        "# Apply one-hot encoding to each feature in the nominal_features list\n",
        "for feature, prefix in zip(nominal_features, nominal_prefixes):\n",
        "    data = onehot_encode_alternative(data, feature, prefix)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OAK03zNlXp40"
      },
      "outputs": [],
      "source": [
        "# Apply ordinal encoding to the 'StageID' column\n",
        "data = ordinal_encode_alternative(data, 'StageID', stage_ordering)\n",
        "\n",
        "# Apply ordinal encoding to the 'GradeID' column\n",
        "data = ordinal_encode_alternative(data, 'GradeID', grade_ordering)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P6eQdDK0X2eF"
      },
      "outputs": [],
      "source": [
        "# Define the ordering for the target column 'Class'\n",
        "target_ordering = ['L', 'M', 'H']\n",
        "\n",
        "# Apply ordinal encoding to the target column\n",
        "encoded_data = ordinal_encode_alternative(data, target_column, target_ordering)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3luxSmKhZSYM"
      },
      "outputs": [],
      "source": [
        "# Display the first 10 rows of the encoded DataFrame to verify the transformations\n",
        "encoded_data.head(10)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the shape of the DataFrame after encoding to verify the dimensions\n",
        "print(data.shape)\n"
      ],
      "metadata": {
        "id": "H3QvhSOwkGun"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract the column names from the encoded DataFrame into a list\n",
        "columns_list = encoded_data.columns.tolist()\n",
        "\n",
        "# Enumerate through the list of column names and print each with its index\n",
        "for index, column_name in enumerate(columns_list):\n",
        "    print(f\"{index + 1}. {column_name}\")\n"
      ],
      "metadata": {
        "id": "qy5LaswQkdBG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the number of missing values in each column of the encoded DataFrame\n",
        "missing_values = encoded_data.isnull().sum()\n",
        "\n",
        "# Print the missing values for each column to identify any issues\n",
        "print(\"Missing Values:\\n\", missing_values)\n"
      ],
      "metadata": {
        "id": "oA5IFH0xAKFE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display the first few rows of the encoded DataFrame to verify the changes\n",
        "encoded_data.head()\n"
      ],
      "metadata": {
        "id": "jmrbzO15yckG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Feature Engineering**"
      ],
      "metadata": {
        "id": "kjBYDGWGOMHW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Select relevant features for modeling by dropping the target column 'Class'\n",
        "numerical_features = encoded_data[['raisedhands', 'VisITedResources', 'AnnouncementsView', 'Discussion']]\n",
        "\n",
        "# Plot a box plot to visualize the distribution of features before standardization\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.boxplot(data=numerical_features)\n",
        "plt.title('Box Plot Before Standardization')\n",
        "plt.xticks(rotation=90)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "CIenA5V4_mr7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "m_-JzJaNfXpF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import StandardScaler for feature standardization\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Standardize the features\n",
        "scaler = StandardScaler()\n",
        "scaled_features = scaler.fit_transform(numerical_features)\n",
        "\n",
        "# Create a DataFrame with the standardized features\n",
        "scaled_features_df = pd.DataFrame(scaled_features, columns=numerical_features.columns)\n",
        "\n",
        "# Plot a box plot to visualize the distribution of features after standardization\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.boxplot(data=scaled_features_df)\n",
        "plt.title('Box Plot After Standardization')\n",
        "plt.xticks(rotation=90)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "PAQRc8yBqF_g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary library\n",
        "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
        "\n",
        "# List of columns to remove due to low VIF values\n",
        "low_vif_columns = [ ]\n",
        "\n",
        "# Remove the columns with low VIF values\n",
        "final_features_df = numerical_features.drop(columns=low_vif_columns)\n",
        "\n",
        "# Recalculate VIF for the reduced dataset\n",
        "vif_final_data = pd.DataFrame()\n",
        "vif_final_data[\"feature\"] = final_features_df.columns\n",
        "vif_final_data[\"VIF\"] = [variance_inflation_factor(final_features_df.values, i) for i in range(len(final_features_df.columns))]\n",
        "\n",
        "# Display final VIF values\n",
        "print(vif_final_data)\n"
      ],
      "metadata": {
        "id": "HVssCT3WAhos"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoded_data['raisedhands'] = numerical_features['raisedhands']\n",
        "encoded_data['VisITedResources'] = numerical_features['VisITedResources']\n",
        "encoded_data['AnnouncementsView'] = numerical_features['AnnouncementsView']\n",
        "encoded_data['Discussion'] = numerical_features['Discussion']"
      ],
      "metadata": {
        "id": "oQ32YHz0hnih"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check for missing values in the VIF DataFrame\n",
        "missing_values = encoded_data.isnull().sum()\n",
        "\n",
        "# Print the number of missing values to ensure data integrity\n",
        "print(\"Missing Values:\\n\", missing_values)\n"
      ],
      "metadata": {
        "id": "e9Fslk13QsFf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display the column names of the DataFrame to verify the current set of features\n",
        "encoded_data.columns\n"
      ],
      "metadata": {
        "id": "SK9lFMt3UVwT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary library for creating annotated heatmap\n",
        "import plotly.figure_factory as ff\n",
        "\n",
        "# Identify numerical columns in the DataFrame\n",
        "numerical_cols = [col for col in encoded_data.columns if encoded_data[col].dtype != 'object']\n",
        "\n",
        "# Calculate the correlation matrix for the numerical columns\n",
        "correlation_matrix = encoded_data[numerical_cols].corr()\n",
        "\n",
        "# Create an annotated heatmap for the correlation matrix\n",
        "fig = ff.create_annotated_heatmap(\n",
        "    z=correlation_matrix.to_numpy(),\n",
        "    x=correlation_matrix.columns.tolist(),\n",
        "    y=correlation_matrix.columns.tolist(),\n",
        "    colorscale='Viridis',\n",
        "    reversescale=True,\n",
        "    annotation_text=correlation_matrix.round(2).values,\n",
        "    font_colors=['white', 'black'],\n",
        ")\n",
        "\n",
        "# Update the layout of the heatmap for better visualization\n",
        "fig.update_layout(\n",
        "    title='Correlation Matrix',\n",
        "    xaxis_title='Features',\n",
        "    yaxis_title='Features',\n",
        "    yaxis_autorange='reversed',\n",
        "    font=dict(size=10),\n",
        "    width=1500,\n",
        "    height=1500\n",
        ")\n",
        "\n",
        "# Show the heatmap\n",
        "fig.show()\n"
      ],
      "metadata": {
        "id": "RmLPLyi6M8Nu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoded_data.drop(['S_A'], axis=1, inplace=True)"
      ],
      "metadata": {
        "id": "hY-6N7ZQNUL1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary library for creating annotated heatmap\n",
        "import plotly.figure_factory as ff\n",
        "\n",
        "# Identify numerical columns in the DataFrame\n",
        "numerical_cols = [col for col in encoded_data.columns if encoded_data[col].dtype != 'object']\n",
        "\n",
        "# Calculate the correlation matrix for the numerical columns\n",
        "correlation_matrix = encoded_data[numerical_cols].corr()\n",
        "\n",
        "# Create an annotated heatmap for the correlation matrix\n",
        "fig = ff.create_annotated_heatmap(\n",
        "    z=correlation_matrix.to_numpy(),\n",
        "    x=correlation_matrix.columns.tolist(),\n",
        "    y=correlation_matrix.columns.tolist(),\n",
        "    colorscale='Viridis',\n",
        "    reversescale=True,\n",
        "    annotation_text=correlation_matrix.round(2).values,\n",
        "    font_colors=['white', 'black'],\n",
        ")\n",
        "\n",
        "# Update the layout of the heatmap for better visualization\n",
        "fig.update_layout(\n",
        "    title='Correlation Matrix',\n",
        "    xaxis_title='Features',\n",
        "    yaxis_title='Features',\n",
        "    yaxis_autorange='reversed',\n",
        "    font=dict(size=10),\n",
        "    width=1500,\n",
        "    height=1500\n",
        ")\n",
        "\n",
        "# Show the heatmap\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "hpkq4JSSNpK2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = encoded_data.drop(['Class'], axis=1)\n",
        "y = encoded_data['Class']"
      ],
      "metadata": {
        "id": "juErzEmSk4Fy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Splitting**"
      ],
      "metadata": {
        "id": "DBrrwyOuPGd6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.20, random_state=42)"
      ],
      "metadata": {
        "id": "Lls2ZUTrDpDT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Naive Bayes**"
      ],
      "metadata": {
        "id": "SZVey4w2ECqf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.naive_bayes import GaussianNB\n",
        "nb = GaussianNB()\n",
        "nb.fit(x_train, y_train)"
      ],
      "metadata": {
        "id": "FQNVC5JqDrba"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_train_nb = nb.predict(x_train)\n",
        "y_pred_test_nb = nb.predict(x_test)"
      ],
      "metadata": {
        "id": "2nxtGhwVnN6-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score\n",
        "\n",
        "accuracy_train_nb = accuracy_score(y_train, y_pred_train_nb)\n",
        "accuracy_test_nb = accuracy_score(y_test, y_pred_test_nb)\n",
        "print(\"Accuracy on Training Set:\", accuracy_train_nb)\n",
        "print(\"Accuracy on Test Set:\", accuracy_test_nb)"
      ],
      "metadata": {
        "id": "EWT2IthiDt8k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "confusion_matrix(y_test, y_pred_test_nb)"
      ],
      "metadata": {
        "id": "Ipe7sYE2Dvxo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "p = precision_score(y_test, y_pred_test_nb, average='weighted')\n",
        "r = recall_score(y_test, y_pred_test_nb, average='weighted')\n",
        "print(\"Precision:\", p)\n",
        "print(\"Recall:\", r)"
      ],
      "metadata": {
        "id": "riKbBQwjp0gU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **KNN**"
      ],
      "metadata": {
        "id": "Sy01WsqCEJxv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "knn = KNeighborsClassifier(n_neighbors=4)\n",
        "knn.fit(x_train, y_train)"
      ],
      "metadata": {
        "id": "C5sPhPZIDyMQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_train_knn = knn.predict(x_train)\n",
        "y_pred_test_knn = knn.predict(x_test)"
      ],
      "metadata": {
        "id": "UECDg2CgDz5s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy_train_knn = accuracy_score(y_train, y_pred_train_knn)\n",
        "accuracy_test_knn = accuracy_score(y_test, y_pred_test_knn)\n",
        "print(\"Accuracy on Training Set:\", accuracy_train_knn)\n",
        "print(\"Accuracy on Test Set:\", accuracy_test_knn)"
      ],
      "metadata": {
        "id": "6EgFYxB-wQPX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "confusion_matrix(y_test, y_pred_test_knn)"
      ],
      "metadata": {
        "id": "HymLX6TJwVLi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import precision_score, recall_score\n",
        "p = precision_score(y_test, y_pred_test_knn, average='weighted')\n",
        "r = recall_score(y_test, y_pred_test_knn, average='weighted')\n",
        "print(\"Precision:\", p)\n",
        "print(\"Recall:\", r)"
      ],
      "metadata": {
        "id": "lm6ZeyspwZhj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Decision Tree**"
      ],
      "metadata": {
        "id": "0tvy6jSuEOJ7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "dt = DecisionTreeClassifier(max_depth=5, min_samples_split=8, min_samples_leaf=4)\n",
        "dt.fit(x_train, y_train)"
      ],
      "metadata": {
        "id": "M3FAkALWD11z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_train_dt = dt.predict(x_train)\n",
        "y_pred_test_dt = dt.predict(x_test)"
      ],
      "metadata": {
        "id": "kRXz-AB35ABh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy_train_dt = accuracy_score(y_train, y_pred_train_dt)\n",
        "accuracy_test_dt = accuracy_score(y_test, y_pred_test_dt)\n",
        "print(\"Accuracy on Training Set:\", accuracy_train_dt)\n",
        "print(\"Accuracy on Test Set:\", accuracy_test_dt)"
      ],
      "metadata": {
        "id": "9jX9KUgk5NQX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Random Forest**"
      ],
      "metadata": {
        "id": "oYSDvZWMEWmz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "rfs = [RandomForestClassifier(n_estimators=150, max_depth=depth, min_samples_split=min_sample, min_samples_leaf=msl, random_state=42) for depth in range(4, 9) for min_sample in range(4, 13) for msl in range(2, 7)]\n"
      ],
      "metadata": {
        "id": "14dfgcAqD37e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def t_and_t(model):\n",
        "  model.fit(x_train, y_train)\n",
        "  y_pred_train_rf = model.predict(x_train)\n",
        "  y_pred_test_rf = model.predict(x_test)\n",
        "\n",
        "  acc_train_rf = accuracy_score(y_train, y_pred_train_rf)\n",
        "  acc_test_rf = accuracy_score(y_test, y_pred_test_rf)\n",
        "  if(acc_test_rf > 0.85):\n",
        "    print(model, acc_train_rf, acc_test_rf)"
      ],
      "metadata": {
        "id": "XSQ1sw0jtNew"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for model in rfs:\n",
        "  t_and_t(model)"
      ],
      "metadata": {
        "id": "lgSL6mNytyca"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rf = RandomForestClassifier(n_estimators=150, max_depth=6, min_samples_split=12, min_samples_leaf=2, random_state=42)\n",
        "rf.fit(x_train, y_train)"
      ],
      "metadata": {
        "id": "ptBOD2oxwBhL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_train_rf = rf.predict(x_train)\n",
        "y_pred_test_rf = rf.predict(x_test)"
      ],
      "metadata": {
        "id": "2WahL_RX6rw1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "acc_train_rf = accuracy_score(y_train, y_pred_train_rf)\n",
        "acc_test_rf = accuracy_score(y_test, y_pred_test_rf)"
      ],
      "metadata": {
        "id": "Bpz9M96f7Gnb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Accuracy on Training Set:\", acc_train_rf)\n",
        "print(\"Accuracy on Test Set:\", acc_test_rf)"
      ],
      "metadata": {
        "id": "PaG43DTI7T6v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "confusion_matrix(y_test, y_pred_test_rf)"
      ],
      "metadata": {
        "id": "moRSn7e3IHYE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "p = precision_score(y_test, y_pred_test_rf, average='weighted')\n",
        "r = recall_score(y_test, y_pred_test_rf, average='weighted')\n",
        "print(\"Precision:\", p)\n",
        "print(\"Recall:\", r)"
      ],
      "metadata": {
        "id": "qDME1FxvILuW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **SVM**"
      ],
      "metadata": {
        "id": "RM6Dk0qTHEYC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVC\n",
        "svm = SVC(kernel='linear')\n",
        "svm.fit(x_train, y_train)"
      ],
      "metadata": {
        "id": "-5kQ0ZiRFohd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_train_svm = svm.predict(x_train)\n",
        "y_pred_test_svm = svm.predict(x_test)"
      ],
      "metadata": {
        "id": "OuFZdUgTHKg2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "acc_train_svm = accuracy_score(y_train, y_pred_train_svm)\n",
        "acc_test_svm = accuracy_score(y_test, y_pred_test_svm)"
      ],
      "metadata": {
        "id": "JiCVOZFFHX8v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Accuracy on Training Set:\", acc_train_svm)\n",
        "print(\"Accuracy on Test Set:\", acc_test_svm)"
      ],
      "metadata": {
        "id": "CTPtvDviHqoO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "confusion_matrix(y_test, y_pred_test_svm)"
      ],
      "metadata": {
        "id": "ynyS2OwTHs4D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "p = precision_score(y_test, y_pred_test_svm, average='weighted')\n",
        "r = recall_score(y_test, y_pred_test_svm, average='weighted')\n",
        "print(\"Precision:\", p)\n",
        "print(\"Recall:\", r)"
      ],
      "metadata": {
        "id": "oOmTGZg3H_VE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Logistic Regression**"
      ],
      "metadata": {
        "id": "sByGzh6DBc90"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "lor = LogisticRegression()\n",
        "lor.fit(x_train, y_train)"
      ],
      "metadata": {
        "id": "ZmzKlgI0_sCa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_train_lor = lor.predict(x_train)\n",
        "y_pred_test_lor = lor.predict(x_test)"
      ],
      "metadata": {
        "id": "YVS3C-g1_1tX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "acc_lor_train = accuracy_score(y_train, y_pred_train_lor)\n",
        "acc_lor_test = accuracy_score(y_test, y_pred_test_lor)"
      ],
      "metadata": {
        "id": "tEy6YeNs_9lc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "acc_lor_test, acc_lor_train"
      ],
      "metadata": {
        "id": "X2Nhvg9DABSR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "confusion_matrix(y_test, y_pred_test_lor)"
      ],
      "metadata": {
        "id": "jN8eBsqEC82U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "percision_lor_test = precision_score(y_test, y_pred_test_lor, average='weighted')\n",
        "recall_lor_test = recall_score(y_test, y_pred_test_lor, average='weighted')\n",
        "\n",
        "percision_lor_test, recall_lor_test"
      ],
      "metadata": {
        "id": "coWIq4oECp2C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **ANN**"
      ],
      "metadata": {
        "id": "-dw6KgA_FoxM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neural_network import MLPClassifier\n",
        "ann = MLPClassifier(hidden_layer_sizes=198, max_iter=85)\n",
        "ann.fit(x_train, y_train)"
      ],
      "metadata": {
        "id": "QMHTMbWnFoId"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_train_ann = ann.predict(x_train)\n",
        "y_pred_test_ann = ann.predict(x_test)"
      ],
      "metadata": {
        "id": "CXOrhGxKF3dJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "acc_ann_train = accuracy_score(y_train, y_pred_train_ann)\n",
        "acc_ann_test = accuracy_score(y_test, y_pred_test_ann)\n",
        "\n",
        "acc_ann_train, acc_ann_test"
      ],
      "metadata": {
        "id": "3hGYri_2F7pZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Random Forest Visualization**"
      ],
      "metadata": {
        "id": "uAJ5-EEZ1ACL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "uqgVdm3Yriye"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "conf_matrix_train = confusion_matrix(y_train, y_pred_train_rf)\n",
        "conf_matrix_test = confusion_matrix(y_test, y_pred_test_rf)\n",
        "\n",
        "fig, ax = plt.subplots(1, 2, figsize=(12, 6))\n",
        "\n",
        "sns.heatmap(conf_matrix_train, annot=True, fmt='d', cmap='Blues', ax=ax[0])\n",
        "ax[0].set_title('Confusion Matrix - Training Set')\n",
        "ax[0].set_xlabel('Predicted Labels')\n",
        "ax[0].set_ylabel('True Labels')\n",
        "\n",
        "sns.heatmap(conf_matrix_test, annot=True, fmt='d', cmap='Blues', ax=ax[1])\n",
        "ax[1].set_title('Confusion Matrix - Test Set')\n",
        "ax[1].set_xlabel('Predicted Labels')\n",
        "ax[1].set_ylabel('True Labels')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "IyAcmlmBr_mA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import plot_tree\n",
        "\n",
        "estimator = rf.estimators_[0]\n",
        "\n",
        "plt.figure(figsize=(20,10))\n",
        "plot_tree(estimator,\n",
        "          feature_names=x_train.columns,\n",
        "          class_names=['0', '1', '2'],\n",
        "          filled=True,\n",
        "          rounded=True)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "tiztXFxSobX9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "importances = rf.feature_importances_\n",
        "\n",
        "indices = np.argsort(importances)[::-1]\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.title(\"Feature Importance\")\n",
        "plt.bar(range(x_train.shape[1]), importances[indices], align=\"center\")\n",
        "plt.xticks(range(x_train.shape[1]), x_train.columns[indices], rotation=90)\n",
        "plt.xlim([-1, x_train.shape[1]])\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "hT-ikLHTOxfz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ysUlDZQOXAg9"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}